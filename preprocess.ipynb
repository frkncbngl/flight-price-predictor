{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Because we have shown how to clean the data in a [different repository](https://github.com/frkncbngl/pandas-data-cleaning) we will explain only the differences and show you how you can create the main model that was trained, instead of the smaller version that was created due to GitHub's and Streamlit Cloud's file size limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now since we have more than 1 file, we need to find them and store them in list, after that we will do the something similar to what we did in the other repository. We will append our dataframe for every file and every sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMSSFO.xlsx', 'AMSCPT.xlsx', 'LHRDXB.xlsx', 'LHRNYC.xlsx', 'LHRBKK.xlsx', 'AMSKUL.xlsx', 'LHRSIN.xlsx', 'AMSSIN.xlsx', 'AMSTHR.xlsx', 'LHRIKA.xlsx', 'AMSBKK.xlsx', 'LHRKUL.xlsx', 'AMSNYC.xlsx', 'LHRCPT.xlsx', 'AMSDXB.xlsx', 'LHRSFO.xlsx']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_xlsx_files(directory):\n",
    "    xlsx_files = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".xlsx\"):\n",
    "            xlsx_files.append(file)\n",
    "    return xlsx_files\n",
    "\n",
    "directory = r\"/path/folder\"\n",
    "xlsx_files = get_xlsx_files(directory)\n",
    "print(xlsx_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = []\n",
    "for file in xlsx_files:\n",
    "    file = pd.ExcelFile(file)\n",
    "    for sheet in file.sheet_names:\n",
    "        df = file.parse(sheet)\n",
    "        list_of_dfs.append(df)\n",
    "data = pd.concat(list_of_dfs,ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"Advisory filter_alt\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = [\"price\",\"carrier\",\"depart_time\",\"arrive_time\",\"duration\",\"from_to\",\"stops\",\"start_date\",\"end_date\"]\n",
    "data.columns = new_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something changes here, earlier we had only Euros as currency, but because of the data scraped now has Pounds, we need to convert them aswell. And we also need to use the current exchange rate while converting. Which is approx 1.17€ for 1 £."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_column_cleaner(row):\n",
    "    if \"£\" in row:\n",
    "        row = row.replace(\"£\",\"\")\n",
    "        row = row.replace(\",\",\"\")\n",
    "        row = int(row)*1.17\n",
    "        return int(row)\n",
    "    elif \"€\" in row:\n",
    "        row = row.replace(\"€\",\"\")\n",
    "        row = row.replace(\",\",\"\")\n",
    "        return int(row)\n",
    "    else:\n",
    "        return int(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"price\"] = data[\"price\"].apply(price_column_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"price\"] = data[\"price\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"stops_list\"] = data[\"stops\"].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_stops(row):\n",
    "    #This function will be used in apply method. \n",
    "    # We use if/else conditions to check if the type of that \"cell\" is a list or not. \n",
    "    # If it is a list it means split method successfully seperated the entire column on a space, if not it still is a Nan. \n",
    "    # So we can check if the \"cell\" contains a list, and if so we can count the items within that list and return it as a stops count.\n",
    "    \n",
    "    if type(row[\"stops_list\"]) == list:\n",
    "        total_stops=len(row[\"stops_list\"])\n",
    "    else:\n",
    "        total_stops = 0\n",
    "    return total_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"total_stops\"] = data.apply(count_stops,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"arrive_time\",\"stops\",\"stops_list\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will return a dataframe with no column names.\n",
    "depart = data[\"depart_time\"].str.extract(r\"(\\d+:\\d+ [APM]+)(\\d+:\\d+ [APM]+)\")\n",
    "depart_column_names = [\"dep_time_outbound\",\"dep_time_inbound\"]\n",
    "depart.columns = depart_column_names\n",
    "data.drop(\"depart_time\",axis=1,inplace=True)\n",
    "data = pd.concat([data,depart],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = data[\"duration\"].str.extract(r\"(\\d+[h] \\d+[m])( \\d+[h] \\d+[m])\")\n",
    "durations_column_names = [\"duration_outbound\",\"duration_inbound\"]\n",
    "durations.columns = durations_column_names\n",
    "data.drop(\"duration\",axis=1,inplace=True)\n",
    "data = pd.concat([data,durations],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_to =data[\"from_to\"].str.extract(r'([A-Z][A-Z]+) to ([A-Z][A-Z]+)')\n",
    "from_to_column_names =  [\"from\",\"to\"]\n",
    "from_to.columns = from_to_column_names\n",
    "data = pd.concat([data,from_to],axis=1)\n",
    "data.drop(\"from_to\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"carrier\"] = data[\"carrier\"].apply(lambda x:x.strip().split(\",\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"day_of_week\"] = pd.to_datetime(data[\"start_date\"]).dt.day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_minutes(time_string):\n",
    "  time_delta = pd.to_timedelta(time_string)\n",
    "  minutes = time_delta.total_seconds() / 60\n",
    "  return minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"outbound_duration_minutes\"] = data[\"duration_outbound\"].apply(to_minutes)\n",
    "data[\"inbound_duration_minutes\"] = data[\"duration_inbound\"].apply(to_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_time_of_day(time_string):\n",
    "  hour = int(time_string.split(\":\")[0])  #Extracting hour from time string\n",
    "  am_pm = time_string.split(\"AM\")[-1]  #Extract AM/PM indicator\n",
    "\n",
    "  if am_pm == \"PM\" and hour != 12:  #Adjusting for hours that represent PM.\n",
    "    hour += 12\n",
    "\n",
    "  #Classifying hours to time of days.\n",
    "  if 5 <= hour < 12:\n",
    "    return \"Morning\"\n",
    "  elif 12 <= hour < 17:\n",
    "    return \"Afternoon\"\n",
    "  elif 17 <= hour < 20:\n",
    "    return \"Evening\"\n",
    "  elif 20 <= hour < 24:\n",
    "    return \"Night\"\n",
    "  else:\n",
    "    return \"Early Morning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"time_of_day_outbound\"] = data[\"dep_time_outbound\"].apply(to_time_of_day)\n",
    "data[\"time_of_day_inbound\"] = data[\"dep_time_inbound\"].apply(to_time_of_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"day_of_year\"] = pd.to_datetime(data[\"start_date\"]).dt.day_of_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important note! We convert differnt airports in the same city to city code. So;\n",
    "- LGA, EWR, JFK to NYC\n",
    "- XNB to DXB\n",
    "- DMK to BKK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"to\"] = data[\"to\"].replace(\"LGA\",\"NYC\")\n",
    "data[\"to\"] = data[\"to\"].replace(\"EWR\",\"NYC\")\n",
    "data[\"to\"] = data[\"to\"].replace(\"JFK\",\"NYC\")\n",
    "data[\"to\"] = data[\"to\"].replace(\"XNB\",\"DXB\")\n",
    "data[\"to\"] = data[\"to\"].replace(\"DMK\",\"BKK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"month_number\"] = pd.to_datetime(data[\"start_date\"]).dt.month\n",
    "data[\"day_of_month\"] = pd.to_datetime(data[\"start_date\"]).dt.day\n",
    "data[\"month_number_end\"] = pd.to_datetime(data[\"end_date\"]).dt.month\n",
    "data[\"day_of_month_end\"] = pd.to_datetime(data[\"end_date\"]).dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
